% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/importance.R
\name{importance_weight}
\alias{importance_weight}
\title{Convert an Embedding Method to a Weighted Version}
\usage{
importance_weight(method)
}
\arguments{
\item{method}{Embedding method to convert into an importance weighted
version.}
}
\value{
Converted embedding method.
}
\description{
Modifies the similarity kernel of an embedding method so that each
weight is further multiplied by the importance of the two observations the
weight was based on.
}
\details{
The new weight matrix, which we'll call the "importance" weight matrix, is
calculated as

\deqn{W_{imp} = WM}{W_imp = W*M}

where W is the original weight matrix and M is the importance matrix, which
is the outer product of an importance vector d with the same length as the
number of observations in the dataset, i.e.:

\deqn{M_{ij} = d_{i}d_{j}}{M_ij = di * dj}

In the originating paper by Yang and co-workers, they suggest using the
degree centrality of each observation as the importance. This involves
interpreting the input probability matrix as a weighted adjacency matrix,
i.e. treat the dataset as a fully connected graph, with weighted edges, where
the weight for the edge between observation i and j is the input probability,
p_ij.
}
\references{
Yang, Z., Peltonen, J., & Kaski, S. (2014).
Optimization equivalence of divergences improves neighbor embedding.
In \emph{Proceedings of the 31st International Conference on Machine Learning (ICML-14)}
(pp. 460-468).
}

