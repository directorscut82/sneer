% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim_grad.R
\name{nesterov_grad_pos}
\alias{nesterov_grad_pos}
\title{Nesterov Accelerated Gradient Calculation}
\usage{
nesterov_grad_pos(opt, inp, out, method, iter)
}
\arguments{
\item{opt}{Optimizer.}

\item{inp}{Input data.}

\item{out}{Output data.}

\item{method}{Embedding method.}

\item{iter}{Iteration number.}
}
\value{
List containing:
 \item{\code{km}}{Stiffness matrix.}
 \item{\code{gm}}{Gradient matrix.}
}
\description{
This function calculates the gradient at a position determined by applying
the momentum update to the current solution position.
}
\references{
Sutskever, I., Martens, J., Dahl, G., & Hinton, G. (2013).
On the importance of initialization and momentum in deep learning.
In \emph{Proceedings of the 30th international conference on machine learning (ICML-13)}
(pp. 1139-1147).
}

