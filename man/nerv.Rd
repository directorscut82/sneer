% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nerv.R
\name{nerv}
\alias{nerv}
\title{Neighbor Retrieval Visualizer (NeRV)}
\usage{
nerv(lambda = 0.5, eps = .Machine$double.eps, verbose = TRUE)
}
\arguments{
\item{lambda}{Weighting factor controlling the emphasis placed on precision
(set \code{lambda} to 0), versus recall (set \code{lambda} to 1). If set to
1, then the method is equivalent to ASNE. Must be a value between 0 and 1.}

\item{eps}{Small floating point value used to prevent numerical problems,
e.g. in gradients and cost functions.}

\item{verbose}{If \code{TRUE}, log information about the embedding.}
}
\value{
An embedding method for use by an embedding function.
}
\description{
A probability-based embedding method.
}
\details{
NeRV is a variant of Asymmetric Stochastic Neighbor Embedding
(see \code{\link{asne}}), with a modified cost function: in addition to
calculating the Kullback-Leibler divergence of the output probabilities Q,
from the input probabilities, P, it also includes the divergence of P from Q.
The final cost function is a weighted sum of these two individual functions.
Hence ASNE is a special case of NeRV where all the weight is placed on the
first component of the cost function.

From an information retrieval perspective, the weighting factor allows the
user to place a relative weight on false positives: points on the embedded
map which have a close distance, but a low input probability, i.e. should not
have been embedded as close neighbors, versus false negatives: pairs with a
large distance in the output coordinates, but a high input probability, i.e.
should have been embedded as close neighbors. From this perspective, ASNE
is the equivalent of emphasising false positives over false negatives.

The probability matrix used in NeRV:

\itemize{
 \item{represents one N row-wise probability distributions, where N is the
 number of points in the data set, i.e. the row sums of the matrix are all
  one.}
 \item{is asymmetric, i.e. there is no requirement that
 \code{p[i, j] == p[j, i]}.}
}
}
\section{Output Data}{

If used in an embedding, the output data list will contain:
\describe{
 \item{\code{ym}}{Embedded coordinates.}
 \item{\code{qm}}{Joint probability matrix based on the weight matrix
 \code{wm}.}
}
}
\examples{
\dontrun{
# default NeRV settings
embed_prob(method = nerv(lambda = 0.5), ...)

# equivalent to ASNE
embed_prob(method = nerv(lambda = 1), ...)

# puts an emphasis on only keeping true neighbors close together
# tends to produce a larger number of small, tight clusters
embed_prob(method = nerv(lambda = 0), ...)
}
}
\references{
Venna, J., Peltonen, J., Nybo, K., Aidos, H., & Kaski, S. (2010).
Information retrieval perspective to nonlinear dimensionality reduction for
data visualization.
\emph{Journal of Machine Learning Research}, \emph{11}, 451-490.
}
\seealso{
NeRV uses the \code{\link{nerv_cost}} cost function and the
  \code{\link{exp_weight}} similarity function for converting distances to
  probabilities.
The return value of this function should be used with the
\code{\link{embed_prob}} embedding function.

Other sneer embedding methods: \code{\link{asne}},
  \code{\link{embedding_methods}}, \code{\link{hsnerv}},
  \code{\link{hssne}}, \code{\link{mmds}},
  \code{\link{sammon_map}}, \code{\link{smmds}},
  \code{\link{snerv}}, \code{\link{ssne}},
  \code{\link{tasne}}, \code{\link{tnerv}},
  \code{\link{tsne}}

Other sneer probability embedding methods: \code{\link{asne}},
  \code{\link{hsnerv}}, \code{\link{hssne}},
  \code{\link{probability_embedding_methods}},
  \code{\link{snerv}}, \code{\link{ssne}},
  \code{\link{tasne}}, \code{\link{tnerv}},
  \code{\link{tsne}}
}

