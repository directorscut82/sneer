% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nerv.R
\name{nerv}
\alias{nerv}
\title{Neighbor Retrieval Visualizer (NeRV)}
\usage{
nerv(lambda = 0.5, eps = .Machine$double.eps, verbose = TRUE)
}
\arguments{
\item{lambda}{Weighting factor controlling the emphasis placed on precision
(set \code{lambda} to 0), versus recall (set \code{lambda} to 1). If set to
1, then the method is equivalent to ASNE. Must be a value between 0 and 1.}

\item{eps}{Small floating point value used to prevent numerical problems,
e.g. in gradients and cost functions.}

\item{verbose}{If \code{TRUE}, log information about the embedding.}
}
\value{
An embedding method for use by an embedding function.
}
\description{
A probability-based embedding method.
}
\details{
NeRV is a variant of Asymmetric Stochastic Neighbor Embedding
(see \code{asne}), with a modified cost function: in addition to
calculating the Kullback-Leibler divergence of the output probabilities Q,
from the input probabilities, P, it also includes the divergence of P from Q.
The final cost function is a weighted sum of these two individual functions.
Hence ASNE is a special case of NeRV where all the weight is placed on the
first component of the cost function.

From an information retrieval perspective, the weighting factor allows the
user to place a relative weight on false positives: points on the embedded
map which have a close distance, but a low input probability, i.e. should not
have been embedded as close neighbors, versus false negatives: pairs with a
large distance in the output coordinates, but a high input probability, i.e.
should have been embedded as close neighbors. From this perspective, ASNE
is the equivalent of emphasising false positives over false negatives.

Additionally, where ASNE uses an exponential function with a parameter set
to 1 for all pairs of points for its output weighting function, NeRV uses
the parameters calculated from the input probability matrix which can (and
do) vary for each observation in the data set. For a more direct compairson
with ASNE, use the uniform NeRV method \code{unerv} which uses one parameter
for all weight generation in the output.

The parameter associated with the exponential kernel is sometimes referred
to as the "precision" in the literature (and in other parts of the help
text). NeRV already uses the term "precision" as defined in terms of
information retrieval, so when referring to the output weighting kernel
function, what's called the "precision" in other parts of the documentation
is just called the kernel parameter (or "bandwidth") when talking about NeRV.

The probability matrix used in NeRV:

\itemize{
 \item{represents one N row-wise probability distributions, where N is the
 number of points in the data set, i.e. the row sums of the matrix are all
  one.}
 \item{is asymmetric, i.e. there is no requirement that
 \code{p[i, j] == p[j, i]}.}
}
}
\section{Output Data}{

If used in an embedding, the output data list will contain:
\describe{
 \item{\code{ym}}{Embedded coordinates.}
 \item{\code{qm}}{Joint probability matrix based on the weight matrix
 \code{wm}.}
}
}
\examples{
\dontrun{
# default NeRV settings
embed_prob(method = nerv(lambda = 0.5), ...)

# equivalent to ASNE or emphasis on recall over precision
embed_prob(method = nerv(lambda = 1), ...)

# puts emphasis on precision over recall
embed_prob(method = nerv(lambda = 0), ...)
}
}
\references{
Venna, J., Peltonen, J., Nybo, K., Aidos, H., & Kaski, S. (2010).
Information retrieval perspective to nonlinear dimensionality reduction for
data visualization.
\emph{Journal of Machine Learning Research}, \emph{11}, 451-490.
}
\seealso{
NeRV uses the \code{nerv_cost} cost function and the
  \code{exp_weight} similarity function for converting distances to
  probabilities.
The return value of this function should be used with the
\code{embed_prob} embedding function.

Other sneer embedding methods: \code{\link{asne_plugin}},
  \code{\link{asne}}, \code{\link{hsjse_plugin}},
  \code{\link{hsnerv_plugin}}, \code{\link{hsnerv}},
  \code{\link{hssne_plugin}}, \code{\link{hssne}},
  \code{\link{jse_plugin}}, \code{\link{mmds}},
  \code{\link{nerv_plugin}}, \code{\link{plugin}},
  \code{\link{rasne_plugin}}, \code{\link{rasne}},
  \code{\link{rssne_plugin}}, \code{\link{rssne}},
  \code{\link{rtsne_plugin}}, \code{\link{rtsne}},
  \code{\link{sammon_map}}, \code{\link{sjse_plugin}},
  \code{\link{smmds}}, \code{\link{snerv_plugin}},
  \code{\link{snerv}}, \code{\link{ssne_plugin}},
  \code{\link{ssne}}, \code{\link{tasne_plugin}},
  \code{\link{tasne}}, \code{\link{tnerv_plugin}},
  \code{\link{tnerv}}, \code{\link{tsne_plugin}},
  \code{\link{tsne}}, \code{\link{uhsnerv_plugin}},
  \code{\link{uhsnerv}}, \code{\link{unerv_plugin}},
  \code{\link{unerv}}, \code{\link{usnerv_plugin}},
  \code{\link{usnerv}}

Other sneer probability embedding methods: \code{\link{asne_plugin}},
  \code{\link{asne}}, \code{\link{hsjse_plugin}},
  \code{\link{hsnerv_plugin}}, \code{\link{hsnerv}},
  \code{\link{hssne_plugin}}, \code{\link{hssne}},
  \code{\link{jse_plugin}}, \code{\link{nerv_plugin}},
  \code{\link{plugin}},
  \code{\link{probability_embedding_methods}},
  \code{\link{rasne_plugin}}, \code{\link{rasne}},
  \code{\link{rssne_plugin}}, \code{\link{rssne}},
  \code{\link{rtsne_plugin}}, \code{\link{rtsne}},
  \code{\link{sjse_plugin}}, \code{\link{snerv_plugin}},
  \code{\link{snerv}}, \code{\link{ssne_plugin}},
  \code{\link{ssne}}, \code{\link{tasne_plugin}},
  \code{\link{tasne}}, \code{\link{tnerv_plugin}},
  \code{\link{tnerv}}, \code{\link{tsne_plugin}},
  \code{\link{tsne}}, \code{\link{uhsnerv_plugin}},
  \code{\link{uhsnerv}}, \code{\link{unerv_plugin}},
  \code{\link{unerv}}, \code{\link{usnerv_plugin}},
  \code{\link{usnerv}}
}

