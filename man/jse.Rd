% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/jse.R
\name{jse}
\alias{jse}
\title{Jensen-Shannon Embedding (JSE)}
\usage{
jse(kappa = 0.5, beta = 1, eps = .Machine$double.eps, verbose = TRUE)
}
\arguments{
\item{kappa}{Mixture parameter. If set to 0, then JSE behaves like ASNE. If
set to 1, then JSE behaves like RASNE.}

\item{beta}{The precision of the weighting function.}

\item{eps}{Small floating point value used to prevent numerical problems,
e.g. in gradients and cost functions.}

\item{verbose}{If \code{TRUE}, log information about the embedding.}
}
\value{
An embedding method for use by an embedding function.
}
\description{
A probability-based embedding method.
}
\details{
JSE is a variant of Asymmetric Stochastic Neighbor Embedding
(see \code{\link{asne}}), with a modified cost function that uses the
a slightly modified version of the Generalized Jensen-Shannon Divergence,
rather than the Kullback-Leibler divergence. The JS divergence can be
considered a symmetrized and smoothed version of the KL divergence.

The JSE cost function modifies the JS divergence to allow the degree of
symmetry in the divergence between two probability distributions, P and Q, to
be controlled by a parameter, kappa, which takes a value between 0 and 1
(exclusive). At its default value of 0.5, it reproduces the symmetric
JS divergence. As kappa approaches zero, its behavior approaches that of the
KL divergence, KL(P||Q) (and hence ASNE). As kappa aproaches one, its
behaviour approaches that of the "reverse" KL divergence, KL(Q||P)
(and hence like \code{\link{rasne}}). You won't get exactly identical results
to RASNE and ASNE, because of numerical issues.

The probability matrix used in JSE:

\itemize{
 \item{represents one N row-wise probability distributions, where N is the
 number of points in the data set, i.e. the row sums of the matrix are all
  one.}
 \item{is asymmetric, i.e. there is no requirement that
 \code{p[i, j] == p[j, i]}.}
}
}
\section{Output Data}{

If used in an embedding, the output data list will contain:
\describe{
 \item{\code{ym}}{Embedded coordinates.}
 \item{\code{qm}}{Joint probability matrix based on the weight matrix
 \code{wm}.}
}
}
\examples{
\dontrun{
# default JSE, cost function is symmetric
embed_prob(method = jse(kappa = 0.5), ...)

# equivalent to ASNE
embed_prob(method = jse(kappa = 0), ...)

# equivalent to "reverse" ASNE
embed_prob(method = jse(kappa = 1), ...)
}
}
\references{
Lee, J. A., Renard, E., Bernard, G., Dupont, P., & Verleysen, M. (2013).
Type 1 and 2 mixtures of Kullback-Leibler divergences as cost functions in
dimensionality reduction based on similarity preservation.
\emph{Neurocomputing}, \emph{112}, 92-108.
}
\seealso{
JSE uses the \code{\link{jse_cost}} cost function and the
  \code{\link{exp_weight}} similarity function for converting distances to
  probabilities. The \code{\link{nerv}} embedding method also uses a cost
  function which is the sum of KL divergences, controlled by a parameter,
  and which also reduces to ASNE at one extreme, and to "reverse" ASNE at
  another.
The return value of this function should be used with the
\code{\link{embed_prob}} embedding function.

Other sneer embedding methods: \code{\link{asne_plugin}},
  \code{\link{asne}}, \code{\link{embedding_methods}},
  \code{\link{hsjse_plugin}}, \code{\link{hsjse}},
  \code{\link{hsnerv_plugin}}, \code{\link{hsnerv}},
  \code{\link{hssne_plugin}}, \code{\link{hssne}},
  \code{\link{jse_plugin}}, \code{\link{mmds}},
  \code{\link{nerv_plugin}}, \code{\link{nerv}},
  \code{\link{plugin}}, \code{\link{rasne_plugin}},
  \code{\link{rasne}}, \code{\link{rssne_plugin}},
  \code{\link{rssne}}, \code{\link{rtsne_plugin}},
  \code{\link{rtsne}}, \code{\link{sammon_map}},
  \code{\link{sjse_plugin}}, \code{\link{sjse}},
  \code{\link{smmds}}, \code{\link{snerv_plugin}},
  \code{\link{snerv}}, \code{\link{ssne_plugin}},
  \code{\link{ssne}}, \code{\link{tasne_plugin}},
  \code{\link{tasne}}, \code{\link{tnerv_plugin}},
  \code{\link{tnerv}}, \code{\link{tsne_plugin}},
  \code{\link{tsne}}

Other sneer probability embedding methods: \code{\link{asne_plugin}},
  \code{\link{asne}}, \code{\link{hsjse_plugin}},
  \code{\link{hsjse}}, \code{\link{hsnerv_plugin}},
  \code{\link{hsnerv}}, \code{\link{hssne_plugin}},
  \code{\link{hssne}}, \code{\link{jse_plugin}},
  \code{\link{nerv_plugin}}, \code{\link{nerv}},
  \code{\link{plugin}},
  \code{\link{probability_embedding_methods}},
  \code{\link{rasne_plugin}}, \code{\link{rasne}},
  \code{\link{rssne_plugin}}, \code{\link{rssne}},
  \code{\link{rtsne_plugin}}, \code{\link{rtsne}},
  \code{\link{sjse_plugin}}, \code{\link{sjse}},
  \code{\link{snerv_plugin}}, \code{\link{snerv}},
  \code{\link{ssne_plugin}}, \code{\link{ssne}},
  \code{\link{tasne_plugin}}, \code{\link{tasne}},
  \code{\link{tnerv_plugin}}, \code{\link{tnerv}},
  \code{\link{tsne_plugin}}, \code{\link{tsne}}
}

